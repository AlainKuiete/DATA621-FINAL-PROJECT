---
title: "DATA 621 Final Project"
author: "Farhana Zahir, Vijaya Cherukuri, Scott Reed, Shovon Biswas, Habib Khan, Alain Kuiete Tchoupou"
date: "11/18/2020"
output:
  word_document: default
  html_document: default
---
## OVERVIEW

The self-management of asthma help improve patient health. 
Asthma self-management provide to the patient and caregivers the skills to understand the disease and its treatment.
It teaches them to take medications appropriately, recognize early signs and symptoms of asthma episodes, seek medical care as appropriate, and identify and avoid environmental asthma allergens and irritants 
In this project, we study the characteristics that influence asthma self-management.


```{r eval=TRUE, echo=FALSE, message=FALSE, warning=FALSE, results='hide'}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(psych)
library(GGally)
library(corrplot)
library(DMwR)
library(caret)
library(VIM)
library(glmnet)
library(doParallel)
library(xgboost) 
library(mice)
library(data.table)
library(kableExtra)
library(mlbench)
```




```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
library(haven)
asthma.adult <- read_sas("/home/alain/Documents/DATA621/FinalProject/acbs_2016_adult_public_llcp.sas7bdat")
View(asthma.adult)
```

```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
#write.csv(asthma.adult, "asthma_adult.csv")
#cn <- colnames(asthma.adult)
#write.csv(cn, "asthma_column_name.csv")
```

```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
dim(asthma.adult)
```
The data set come from CDC with ulr = "https://www.cdc.gov/brfss/acbs/2016_documentation.html". It is a survey study.
The download file is "2016 ACBS Adult Data SAS [ZIP – 3.10 MB]"
The unzip file has 899 variables and 13,922 cases.
We have selected the variables to use on our studies. 


## EXPLORATORY DATA ANALYSIS

Meaning of variables used in the dataset

ASTHNOW Have you ever been told by a doctor or other health professional that you have
asthma?

TCH_SIGN  Has a doctor or other health professional ever taught you...
a. How to recognize early signs or symptoms of an asthma episode?

TCH_RESP Has a doctor or other health professional ever taught you...
b. What to do during an asthma episode or attack?

TCH_MON A peak flow meter is a hand held device that measures how quickly you can blow air
out of your lungs. Has a doctor or other health professional ever taught you…
c. How to use a peak flow meter to adjust your daily medications?

MGT_PLAN An asthma action plan, or asthma management plan, is a form with instructions
about when to change the amount or type of medicine, when to call the doctorfor
advice, and when to go to the emergency room.
Has a doctor or other health professional EVER given you an asthma action plan?


MOD_ENV (7.13) INTERVIEWER READ: Now, back to questions specifically about you.
Has a health professional ever advised you to change things in your home, school, or
work to improve your asthma

MGT_CLAS Have you ever taken a course or class on how to manage your asthma?

INHALERH (8.3) Did a doctor or other health professional show you how to use the inhaler?

INHALERW (8.4) Did a doctor or other health professional watch you use the inhaler?

Responses types
(1) YES
(2) NO
(7) DON’T KNOW
(9) REFUSED

Predictors

MISS_DAY = "NUMBER OF MISSED DAYS"

MOD_ENV = "EVER ADVISED CHANGE THINGS IN YOUR HOME"

AGEDX = "AGE AT ASTHMA DIAGNOSIS"

AGEG_F6_M = "MODIFIED SIX AGE GROUPS USED IN ASTHMA ADULT POST-STRATIFICATION"

AIRCLEANER = "AIR CLEANER USED"

ASMDCOST = "COST BARRIER: PRIMARY CARE DOCTOR"

ASRXCOST = "COST BARRIER: MEDICATION"

ASSPCOST = "COST BARRIER: SPECIALIST"

CATTMPTS_F = "DISPOSITION CODES FOR CALL ATTEMPTS 1 THROUGH 20 ..."

EMP_STAT = "CURRENT EMPLOYMENT STATUS"

EPIS_12M = "ASTHMA EPISODE OR ATTACK"

EPIS_TP = "NUMBER OF EPISODES / ATTACKS"

ER_TIMES = "NUMBER OF EMERGENCY ROOM VISITS"

ER_VISIT = "EMERGENCY ROOM VISIT"

EVER_ASTH = "EVER HAVE ASTHMA INCONSISTENT WITH BRFSS"


HOSPPLAN = "HOSPITAL FOLLOW-UP"

HOSPTIME = "NUMBER OF HOSPITAL VISITS"

HOSP_VST = "HOSPITAL VISIT"

QSTLANG_F = "LANGUAGE IDENTIFIER"

SCR_MED3 = "HAVE ALL THE MEDICATIONS"

UNEMP_R = "REASON NOT NOW EMPLOYED"

URG_TIME = "NUMBER OF URGENT VISITS"

WORKENV5 = "ASTHMA AGGRAVATED BY CURRENT JOB"

WORKENV6 = "ASTHMA CAUSED BY CURRENT JOB"

WORKENV7 = "ASTHMA AGGRAVATED BY PREVIOUS JOB"

WORKENV8 = "ASTHMA CAUSED BY PREVIOUS JOB"

WORKQUIT1 = "EVER CHANGE OR QUIT A JOB"

WORKSEN3 = "DOCTOR DIAGNOSED WORK ASTHMA"

WORKSEN4 = "SELF-IDENTIFIED WORK ASTHMA"

WORKTALK = "DOCTOR DISCUSSED WORK ASTHMA"

INS1 = "INSURANCE"

INS2 = "INSURANCE OR COVERAGE GAP"

LASTSYMP = "LAST HAD ANY SYMPTOMS OF ASTHMA"

LAST_MD = "LAST TALKED TO A DOCTOR"

LAST_MED = "LAST TOOK ASTHMA MEDICATION"

COMPASTH = "TYPICAL ATTACK"



### Constructing the Data Frame by Selecting variables
We select all possible variable that we can use in our dataset.
We also start to clean the dataset

```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
asthma.mgt.adult1 <- data.frame(TCH.SIGN = asthma.adult$TCH_SIGN, 
                                TCH.RESP = asthma.adult$TCH_RESP,
                                TCH.MON = asthma.adult$TCH_MON,
                                MGT.PLAN = asthma.adult$MGT_PLAN,
                                MGT.CLAS = asthma.adult$MGT_CLAS,
                                INHALERW = asthma.adult$INHALERW,
                                MOD.ENV = asthma.adult$MOD_ENV,
                                SEX = asthma.adult$SEX,
                                AGEG.F7 = asthma.adult$AGEG_F7,
                                "RACE.GR3" = asthma.adult[, "_RACEGR3"],
                                #"EDUCA" = asthma.adult[, "_EDUCAG"],
                                EDUCAL = asthma.adult$EDUCA,
                                #INCOMEL = asthma.adult$INCOME2,
                                "INCOMG" = asthma.adult[, "_INCOMG"],
                                #"BMISCAT "= asthma.adult[, "_BMI5CAT"],
                                "RFBMIS" = asthma.adult[, "_RFBMI5"],
                                SMOKE100 = asthma.adult$SMOKE100,
                                COPD = asthma.adult$COPD,
                                EMPHY = asthma.adult$EMPHY,
                                DEPRESS = asthma.adult$DEPRESS,
                                BRONCH = asthma.adult$BRONCH,
                                SYMP.30D = asthma.adult$SYMP_30D,
                                DUR.30D = asthma.adult$DUR_30D,
                                #ASLEEP30 = asthma.adult$ASLEEP30,
                                #SYMPFREE = asthma.adult$SYMPFREE,
                                INCINDT = asthma.adult$INCIDNT,
                                LAST.MD = asthma.adult$LAST_MD,
                                LAST.MED = asthma.adult$LAST_MED,
                                LAST.SYMP = asthma.adult$LASTSYMP,
                                EPIS.12M = asthma.adult$EPIS_12M,
                                #EPIS.TP = asthma.adult$EPIS_TP,
                                #DUR.ASTH = asthma.adult$DUR_ASTH,
                                COMPASTH = asthma.adult$COMPASTH,
                                INS1 = asthma.adult$INS1,
                                INS2 = asthma.adult$INS2,
                                #ER.TIMES = asthma.adult$ER_TIMES,
                                ER.VISIT = asthma.adult$ER_VISIT,
                                #URG.TIMES = asthma.adult$URG_TIME,
                                HOSP.VST = asthma.adult$HOSP_VST,
                                #HOSPTIME = asthma.adult$HOSPTIME,
                                #HOSPPLAN = asthma.adult$HOSPPLAN,
                                ASMDCOST = asthma.adult$ASMDCOST,
                                ASRXCOST = asthma.adult$ASRXCOST,
                                ASSPCOST = asthma.adult$ASSPCOST,
                                WORKTALK = asthma.adult$WORKTALK
                                )
```


```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
asthma.mgt.adult2 <- data.frame(apply(asthma.mgt.adult1, 2, as.factor ))
summary(asthma.mgt.adult2)
```



```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
# asthma.mgt.adult2 <- asthma.mgt.adult2 %>%
#   mutate(TCH.SIGN = fct_collapse(TCH.SIGN,
#                                  "1" = "1",
#                                  "2" = "2",
#                                  "7" = c("7", "9")))
# summary(asthma.mgt.adult2$TCH.SIGN)
```

```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
asth.mgt.ad.min <-  asthma.mgt.adult1 %>% filter(TCH.SIGN == 1 | TCH.SIGN == 2, 
                                                 TCH.RESP == 1 | TCH.RESP == 2,
                                                 TCH.MON == 1 | TCH.MON == 2,
                                                 MGT.PLAN == 1 | MGT.PLAN == 2,
                                                 MGT.CLAS == 1 | MGT.CLAS  == 2,
                                                 INHALERW == 1 | INHALERW == 2,
                                                 MOD.ENV == 1 | MOD.ENV == 2)
```

```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
dim(asth.mgt.ad.min)
```


```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
asth.mgt.ad.min2 <- asth.mgt.ad.min
# asth.mgt.ad.min2 <- asth.mgt.ad.min %>% filter(LAST.MD != 77 & LAST.MD != 99,
#                                                LAST.MED != 77 & LAST.MED != 99,
#                                                LAST.SYMP != 77 & LAST.SYMP != 99,LAST.SYMP != 88,
#                                                INCINDT != 7 & INCINDT != 9,
#                                                SYMP.30D != 77 & SYMP.30D != 99,
#                                                DUR.30D != 9 & DUR.30D != 99,
#                                                ASLEEP30 != 99, ASLEEP30 !=66, ASLEEP30 != 100, ASLEEP30 != 111,
#                                                EPIS.12M != 7 & EPIS.12M != 9,
#                                                COMPASTH != 7 & COMPASTH != 9,
#                                                INS1 != 7 & INS1 != 9,
#                                                ER.VISIT != 7 & ER.VISIT != 9,
#                                                ER.TIMES != 777 & ER.TIMES != 999,
#                                                URG.TIMES != 777 & URG.TIMES != 999,
#                                                HOSP.VST != 9,
#                                                HOSPTIME != 777
#                                                )
```





```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
# asth.mgt.ad.min %>% select(DUR.ASTH) %>% filter(DUR.ASTH==0)
```


```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
#dim(asth.mgt.ad.min2)
```


## Structure of the data
```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
str(asth.mgt.ad.min2)
attach(asth.mgt.ad.min2)
```


### Summary of the Data
```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
sum.data <- summary(asth.mgt.ad.min2)
sum.data
write.csv(sum.data, "summary_data.csv")
```




### Distribution of the Variables in the Data

#### Histograms       
Histograms tell us how the data is distributed in the dataset (numeric fields).    

```{r, message = FALSE, warning = FALSE, echo = F}
multi.hist(asthma.mgt.adult1[1:9])
multi.hist(asthma.mgt.adult1[10:18])
multi.hist(asthma.mgt.adult1[19:27])
multi.hist(asthma.mgt.adult1[28:34])
```


### The correlations betweeen predictors

```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
cor_asthma.adult <- cor(asth.mgt.ad.min2[,-c(1:7)], use = "na.or.complete")
corrplot(cor_asthma.adult, order = 'hclust', type = 'lower')
```

```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
# cor(asthma.mgt.adult1[,-1], use = "na.or.complete")
# write.csv(cor(asthma.mgt.adult1[,-1], use = "na.or.complete"), "predictors_cor.csv")
```

There are highly correlated predictors. We are going to remove some of them.

```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
asth.mgt.ad.min21 <- select(asth.mgt.ad.min2, -ASSPCOST, -ASMDCOST)
colnames(asth.mgt.ad.min21)
```

### CONSTRUCT THE RESPONSE VARIABLE
We first extract variables related to education, 
#### Selection of variables
```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
responses <- data.frame(
                        TCH.SIGN = asth.mgt.ad.min21$TCH.SIGN, 
                        TCH.RESP = asth.mgt.ad.min21$TCH.RESP,
                        TCH.MON = asth.mgt.ad.min21$TCH.MON,
                        MGT.PLAN = asth.mgt.ad.min21$MGT.PLAN,
                        MGT.CLAS = asth.mgt.ad.min21$MGT.CLAS,
                        INHALERW = asth.mgt.ad.min21$INHALERW,
                        MOD.ENV = asth.mgt.ad.min21$MOD.ENV
                        )
head(responses)
```

#### Exploration of the clustering
```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
responses.cat <- data.frame(apply(responses, 2, as.factor))
summary(responses.cat)
```

#### Elbow method to find the number of clusters 
We run kmeans with different clusters from 1 to 16 and we produce a scree plot to determine the number of cluster at the elbow.
```{r, eval=TRUE, message=FALSE, warning=FALSE, fig.cap= "Elbow method Scree Plot", echo=FALSE, results='show'}
set.seed(25)
# Initialize total within sum of squares error: wss
wss <- 0

# Look over 1 to 15 possible clusters
for (i in 1:16) {
  # Fit the model: km.out
  km.out <- kmeans(responses.cat, centers = i, nstart = 20, iter.max = 50)
  # Save the within cluster sum of squares
  wss[i] <- km.out$tot.withinss
}

# Produce a scree plot
plot(1:16, wss, type = "b", 
     xlab = "Number of Clusters", 
     ylab = "Within groups sum of squares"
)
```


```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
# Select number of clusters
k <- 3
```
 The number of cluster is 3
 
#### Now we do the clustering and  extract the centers of resulting model
```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
set.seed(25)
# Build model with k clusters: km.out
km.out <- kmeans(responses.cat, centers = k, nstart = 20, iter.max = 50)

# View the resulting model
km.out$centers

```


#### We add the point classification to the original data
```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
resp.asthma <- cbind(responses.cat, target = km.out$cluster)
head(resp.asthma)
write.csv(resp.asthma, "response_interpret.csv")
```


```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
resp.asthma$target <- as.factor(resp.asthma$target)
```

```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
summary(resp.asthma)
```

```{r, eval=TRUE, message=FALSE, warning=FALSE, fig.cap= "View of the clustering result", echo=FALSE, results='show'}
plot(resp.asthma$target)
```


### Interpretation of the Selft-Management Response clustering 
#### TCH.SIGN
```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
egt <- group_by(resp.asthma, TCH.SIGN, target) %>% summarise(count=n()) %>%
  group_by(TCH.SIGN) %>% mutate(etotal=sum(count), proportion=count/etotal)
tibble::as.tibble(egt)
```

```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
 asth.res1 <- egt %>% group_by(TCH.SIGN) %>% mutate(group.max = max(count)) %>% group_by(target) %>% filter(count==group.max)
asth.res1
```



```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
ggplot(egt, aes(x=target, y=proportion, group=TCH.SIGN, linetype=TCH.SIGN))+geom_line()
```
In  the target response, 8 is the positive answer, 3 is the negative answer, 5 is don't know and 6 is refused for the question:
TCH_SIGN  Has a doctor or other health professional ever taught you...
a. How to recognize early signs or symptoms of an asthma episode?



#### TCH.RESP
```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
egt <- group_by(resp.asthma, TCH.RESP, target) %>% summarise(count=n()) %>%
  group_by(TCH.RESP) %>% mutate(etotal=sum(count), proportion=count/etotal)
tibble::as.tibble(egt)
```

```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
asth.res2 <- egt %>% group_by(TCH.RESP) %>% mutate(group.max = max(count)) %>% group_by(target) %>% filter(count==group.max)
asth.res2
```


```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
ggplot(egt, aes(x=target, y=proportion, group=TCH.RESP, linetype=TCH.RESP))+geom_line()
```
In  the target response, 8 is the positive answer, 3 is the negative answer, 1 is don't know and 1 is refused for the question:
TCH_RESP Has a doctor or other health professional ever taught you...
b. What to do during an asthma episode or attack?


#### TCH.MON
```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
egt <- group_by(resp.asthma, TCH.MON, target) %>% summarise(count=n()) %>%
  group_by(TCH.MON) %>% mutate(etotal=sum(count), proportion=count/etotal)
tibble::as.tibble(egt)
```

```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
asth.res3 <- egt %>% group_by(TCH.MON) %>% mutate(group.max = max(count)) %>% group_by(target) %>% filter(count==group.max)
asth.res3
```


```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
ggplot(egt, aes(x=target, y=proportion, group=TCH.MON, linetype=TCH.MON))+geom_line()
```
In  the target response, 8 is the positive answer, 7 are the negative answers, 2 is don't know and 2 is refused for the question:
TCH_MON A peak flow meter is a hand held device that measures how quickly you can blow air
out of your lungs. Has a doctor or other health professional ever taught you…
c. How to use a peak flow meter to adjust your daily medications?



#### MGT.PLAN
```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
egt <- group_by(resp.asthma, MGT.PLAN, target) %>% summarise(count=n()) %>%
  group_by(MGT.PLAN) %>% mutate(etotal=sum(count), proportion=count/etotal)
tibble::as.tibble(egt)
```

```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
asth.res4 <- egt %>% group_by(MGT.PLAN) %>% mutate(group.max = max(count)) %>% group_by(target) %>% filter(count==group.max)
asth.res4
```


```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
ggplot(egt, aes(x=target, y=proportion, group=MGT.PLAN, linetype=MGT.PLAN))+geom_line()
```
In  the target response, 8 is the positive answer, 3 is the negative answer, 9 is don't know and 9 is refused for the question:
MGT_PLAN An asthma action plan, or asthma management plan, is a form with instructions
about when to change the amount or type of medicine, when to call the doctor for
advice, and when to go to the emergency room.
Has a doctor or other health professional EVER given you an asthma action plan?




#### MGT.CLAS
```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
egt <- group_by(resp.asthma, MGT.CLAS, target) %>% summarise(count=n()) %>%
  group_by(MGT.CLAS) %>% mutate(etotal=sum(count), proportion=count/etotal)
tibble::as.tibble(egt)
```

```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
asth.res5 <- egt %>% group_by(MGT.CLAS) %>% mutate(group.max = max(count)) %>% group_by(target) %>% filter(count==group.max)
asth.res5
```


```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
ggplot(egt, aes(x=target, y=proportion, group=MGT.CLAS, linetype=MGT.CLAS))+geom_line()
```
In  the target response, 8 is the positive answer, 8 or(3,7)  is the negative answer, 8 is don't know and 6 is refused for the question:
MGT_CLAS Have you ever taken a course or class on how to manage your asthma?


#### INHALERW 
```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
egt <- group_by(resp.asthma, INHALERW , target) %>% summarise(count=n()) %>%
  group_by(INHALERW ) %>% mutate(etotal=sum(count), proportion=count/etotal)
tibble::as.tibble(egt)
```

```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
asth.res6 <- egt %>% group_by(INHALERW) %>% mutate(group.max = max(count)) %>% group_by(target) %>% filter(count==group.max)
asth.res6
```


```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
ggplot(egt, aes(x=target, y=proportion, group=INHALERW , linetype=INHALERW))+geom_line()
```
In  the target response, 8 is the positive answer, 3 is the negative answer, 4 is don't know and 1 is refused for the question:
INHALERW (8.4) Did a doctor or other health professional watch you use the inhaler?


#### MOD.ENV
```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
egt <- group_by(resp.asthma, MOD.ENV , target) %>% summarise(count=n()) %>%
  group_by(MOD.ENV) %>% mutate(etotal=sum(count), proportion=count/etotal)
tibble::as.tibble(egt)
```


```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
asth.res7 <- egt %>% group_by(MOD.ENV) %>% mutate(group.max = max(count)) %>% group_by(target) %>% filter(count==group.max)
asth.res7
```


```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
ggplot(egt, aes(x=target, y=proportion, group=MOD.ENV, linetype=MOD.ENV))+geom_line()
```


#### Summary  of the response variables
```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
response.var <- data_frame(RESPONSE = c("1=YES", "2=NO"),
                           TCH.SIGN = asth.res1$target,
                           TCH.RES  = asth.res2$target,
                           TCH.MON = asth.res3$target,
                           MGT.PLAN = asth.res4$target,
                           MGT.CLAS = asth.res5$target,
                           INHALERW = asth.res6$target,
                           MOD.ENV = asth.res7$target)
response.var
```
##### For the response variable TARGET, an excellent management skill has number 2 but a poor management skill has number 1 and 3.
##### We can build a logistics regression on the dataset.

```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
resp.asthma2 <- resp.asthma
resp.asthma2$target <- if_else(resp.asthma2$target==2, 1, 0)
```

```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
#?mutate()
```


### Here we remove the varibles used to calculate the target variable and reformat the data frame.
```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
asth.mgt.ad.min31 <- asth.mgt.ad.min21 %>%
  select( -TCH.SIGN,-TCH.RESP, -TCH.MON, -MGT.PLAN, -MGT.CLAS, -INHALERW, -MOD.ENV) %>%
  mutate(TARGET = resp.asthma2$target) %>% relocate(TARGET, .before = SEX)
str(asth.mgt.ad.min31)
```



### PREPARE THE DATA FOR MODELISATION

#### We remove the rows with missing values.
Here were are going to drop missing data because they are only 12  over 13,922 rows.
We also transform all predictors to categorical.
```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
asth.mgt.ad.min33 <- drop_na(asth.mgt.ad.min31)
asth.mgt.ad.min35 <- data.frame(apply(asth.mgt.ad.min33, 2, as.factor))
summary(asth.mgt.ad.min35)
```

#### Visualization of some combine variables
```{r, eval=TRUE, message=FALSE, warning=FALSE, fig.cap= "Proportion of Good Skill Management in terme of Education Level", echo=FALSE, results='show'}
library(dplyr)
egt <- group_by(asth.mgt.ad.min35, EDUCAL, TARGET) %>% summarise(count=n()) %>%
  group_by(EDUCAL) %>% mutate(etotal=sum(count), proportion=count/etotal)
ggplot(egt, aes(x=EDUCAL, y=proportion, group=TARGET, linetype=TARGET))+geom_line()
```

```{r, eval=TRUE, message=FALSE, warning=FALSE, fig.cap= "Proportion of Good skill management in terme of Duration of Asthma Attack", echo=FALSE, results='show'}
egt <- summarize(group_by(asth.mgt.ad.min35, LAST.SYMP, TARGET), count = n())
egt <- mutate(egt, etotal =sum(count), proportion= count/etotal)
ggplot(data=egt, aes(x=LAST.SYMP, y=proportion, group=TARGET, linetype=TARGET))+geom_line()
```




#### Splitting the data into train and test sets
```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
library(caret)
set.seed(25)
inTraining <- createDataPartition(asth.mgt.ad.min35$TARGET, p = .80, list = FALSE)
training1 <- asth.mgt.ad.min35[ inTraining,]
testing1  <- asth.mgt.ad.min35[-inTraining,]
```

### BUILDS MODELS



#### Model using full predictors with glm
```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
glm.all <- glm(TARGET~., data=training1, family=binomial)
glm.all
```




#### Confusion Matrix with the testingset
```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
# glm.pred <- predict(glm.all, newdata = testing1[,-1], type = "response")
# predicted <- as.factor(ifelse(glm.pred>.5,1,0))
# glm.cm <- confusionMatrix(data = predicted, testing1$TARGET, positive = '1')
# glm.cm
```


#### First glm model using backward elimination of step function

```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
glm.mod11 <- step(glm.all, trace = 0)
glm.mod11
```
Call:  glm(formula = TARGET ~ SEX + AGEG.F7 + X_RACEGR3 + EDUCAL + BRONCH + 
    DUR.30D + INCINDT + LAST.MD + LAST.MED + LAST.SYMP + COMPASTH + 
    HOSPTIME + ASRXCOST + WORKTALK, family = binomial, data = training1)

```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
# glm.mod11 <- glm(formula = TARGET ~ SEX + AGEG.F7 + X_RACEGR3 + EDUCAL + BRONCH +
#     DUR.30D + INCINDT + LAST.MD + LAST.MED + LAST.SYMP + COMPASTH +HOSPPLAN+
#    + ASRXCOST + WORKTALK, family = binomial, data = training1)

```

#### Confusion Matrix with the testingset
```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
glm11.pred <- predict(glm.mod11, newdata = testing1[,-1], type = "response")
predicted <- as.factor(ifelse(glm11.pred>.5,1,0))
glm11.cm <- confusionMatrix(data = predicted, testing1$TARGET, positive = '1')
glm11.cm
```


```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}

```

#### Second glm model
```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
glm.mod12 <-  glm(formula = TARGET ~ SEX + AGEG.F7 + X_RACEGR3 + EDUCAL + X_INCOMG + 
    BRONCH + DUR.30D + INCINDT + LAST.MD + LAST.MED + LAST.SYMP + 
    COMPASTH + WORKTALK, family = binomial, data = training1)
glm.mod12
```


#### Confusion Matrix with the testingset
```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
glm12.pred <- predict(glm.mod12, newdata = testing1[,-1], type = "response")
predicted <- as.factor(ifelse(glm12.pred>.5,1,0))
glm12.cm <- confusionMatrix(data = predicted, testing1$TARGET, positive = '1')
glm12.cm
```

#### Lasso and Ridge model

Since our dataset has multiple variable, we can use penalized logistic regression to find an optimal performing model.
Ridge Regression and Lasso Regression have two different approaches. 
Ridge Regression incorporates all variables in the model and gives the coefficients of variables with minor contribution close to zero
Lasso Regression keeps only the most significant variables and gives zero to the coefficient of the rest of variables.

#### Split the data into trainset and testingset, Dumy code categorical predictors
```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
set.seed(25)
inTraining <- createDataPartition(asth.mgt.ad.min33$TARGET, p = .80, list = FALSE)
training2 <- asth.mgt.ad.min33[ inTraining,]
testing2  <- asth.mgt.ad.min33[-inTraining,]
x <- model.matrix(TARGET ~., data = training2)
y = training2$TARGET
xt <- model.matrix(TARGET ~., data = testing2)
yt <- as.factor(testing2$TARGET)

```



#### Ridge Regression 
We fit and obsrve the coefficients of rigde regression against the log of lambda.
```{r, eval=TRUE, message=FALSE, warning=FALSE, fig.cap= "Variation of Ridge Model Coefficient by Log Lambda", echo=FALSE, results='show'}
fit.ridge <- glmnet(x = x,y=y, alpha=0, family="binomial")
plot(fit.ridge, xvar= "lambda", label=TRUE)
```
The coefficients are significative for negative log lambda and start stabilize around -4

```{r, eval=TRUE, message=FALSE, warning=FALSE, fig.cap= "Lambda that Minimises MSE", echo=FALSE, results='show'}
cv.ridge <- cv.glmnet(x = x, y = y, alpha=0)
plot(cv.ridge)
```

The plot shows that the log of the optimal value of lambda (i.e. the one that minimises the root mean square error) is approximately -3. The exact value can be viewed by examining the variable lambda_min in the code below. In general though, the objective of regularisation is to balance accuracy and simplicity. In the present context, this means a model with the smallest number of coefficients that also gives a good accuracy.  To this end, the cv.glmnet function  finds the value of lambda that gives the simplest model but also lies within one standard error of the optimal value of lambda.


```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
cv.ridge$lambda.min
```

#### Confusion matrix with  lambda min
```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
ridge.model1 <- glmnet(x = x,y=y, lambda = cv.ridge$lambda.min, alpha=0, family="binomial")
ridge.pred1 <- predict(ridge.model1, newx = xt)
predicted <- rep(0, length(yt))
predicted[ridge.pred1>0.5] <- "1"
ridge.cm1 <- confusionMatrix(data = as.factor(predicted), yt, positive = '1')
ridge.cm1
```
We observe overfitting with this ridge model



#### Confusion matrix with best lambda
```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
ridge.model2 <- glmnet(x = x,y=y, lambda = cv.ridge$lambda.1se, alpha=0, family="binomial")
ridge.pred2 <- predict(ridge.model2, newx = xt)
predicted <- rep(0, length(yt))
predicted[ridge.pred2>0.5] <- "1"
ridge.cm2 <- confusionMatrix(data = as.factor(predicted), yt, positive = '1')
ridge.cm2
```
We observe overfitting with this second ridge model

#### Getting the coefficients
```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
coef(ridge.model1)
```

##### Lasso Regression

```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
fit.lasso <- glmnet(x =x, y = y, alpha = 1, family = "binomial")
plot(fit.lasso, xvar = "dev", label = TRUE)
```


```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
fit.lasso <- glmnet(x,y)
plot(fit.lasso, xvar = "lambda", label = TRUE)
plot(fit.lasso, xvar = "dev", label = TRUE)
```

#### Find the best lambda using cross validation
```{r, eval=TRUE, message=FALSE, warning=FALSE, fig.cap= "Lambda that minimises MSE in Lasso",echo=FALSE, results='show'}
cv.lasso <- cv.glmnet(x,y)
plot(cv.lasso)
```
The plot shows that the log of the optimal value of lambda (i.e. the one that minimises the root mean square error) is approximately -10. The exact value can be viewed by examining the variable lambda_min in the code below. In general though, the objective of regularisation is to balance accuracy and simplicity. In the present context, this means a model with the smallest number of coefficients that also gives a good accuracy.  To this end, the cv.glmnet function  finds the value of lambda that gives the simplest model but also lies within one standard error of the optimal value of lambda.


#### Confusion Matrix with lambda min

```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
lasso.model1 <- glmnet(x =x, y = y, lambda = cv.lasso$lambda.min, alpha = 1, family = "binomial")
lasso.pred1 <- predict(lasso.model1, newx = xt, type = "response")
predicted <- as.factor(ifelse(lasso.pred1>.5,1,0))
lasso.cm1 <- confusionMatrix(data = predicted, yt, positive = '1')
lasso.cm1
```

#### Getting the coefficients
```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
coef(lasso.model1)
```



#### Confusion Matrix with best lambda

```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
lasso.model2 <- glmnet(x =x, y = y, lambda = cv.lasso$lambda.1se, alpha = 1, family = "binomial")
lasso.pred2 <- predict(lasso.model2, newx = xt, type = "response")
predicted <- as.factor(ifelse(lasso.pred2>.5,1,0))
lasso.cm2 <- confusionMatrix(data = predicted, yt, positive = '1')
lasso.cm2
```


##### Calculating the AICc of Ridge and Lasso Models

```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
AICc <- function(fit){
  tLL <- fit$nulldev - deviance(fit)
  k <- fit$df
  n <- fit$nobs
  AICc <- -tLL+2*k+2*k*(k+1)/(n-k-1)
  return (AICc)
}

```

it <- glmnet(x, y, family = "multinomial") 

tLL <- fit$nulldev - deviance(fit)
k <- fit$df
n <- fit$nobs
AICc <- -tLL+2*k+2*k*(k+1)/(n-k-1)
AICc

```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
AICc(ridge.model1)
AICc(lasso.model1)
```

#### Partial Least Squared
```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
ctrl <- trainControl(method = "repeatedcv", repeats = 3)

plsFit1 <- train(
  TARGET ~ .,
  data = training1,
  method = "pls",
  preProc = c("center", "scale"),
  tuneLength = 15,
  ## added:
  trControl = ctrl
)
```

#### Confusion Matrix with best lambda
```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
pls1.pred <- predict(plsFit1, newdata = testing1[,-1], type = "prob")
pls.pred1 <- predict(plsFit1, newdata = testing1[,-1], type = "raw")
pls.cm1 <- confusionMatrix(data = pls.pred1, testing1$TARGET, positive = '1')
pls.cm1

```

```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
training3 <- training1
testing3 <- testing1
training3$TARGET <- ifelse(training3$TARGET=="1","T","F")
testing3$TARGET <- ifelse(testing3$TARGET=="1","T","F")
```



#### Here we train the model with partial least square using tune parameter.
```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
ctrl <- trainControl(
  method = "repeatedcv", 
  repeats = 3,
  classProbs = TRUE, 
  summaryFunction = twoClassSummary
)

set.seed(123)
plsFit2 <- train(
  TARGET ~ .,
  data = training3,
  method = "pls",
  preProc = c("center", "scale"),
  tuneLength = 15,
  trControl = ctrl,
  metric = "ROC"
)
plsFit2
```

#### Confusion Matrix with best lambda
```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
pls2.pred <- predict(plsFit2, newdata = testing3[,-1], type = "prob")
pls.pred2 <- predict(plsFit2, newdata = testing3[,-1], type = "raw")
pls.cm2 <- confusionMatrix(data = pls.pred1, testing1$TARGET, positive = '1')
pls.cm2

```


### SELECT MODELS
#### We compare the models with the accuray, precision, sensitivity, specificity, and F1 score from the confusion matrix
```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
cm.metric <- function(cm){
  test = c(cm$overall["Accuracy"],
           cm$byClass["Precision"],
           cm$byClass["Sensitivity"],
           cm$byClass["Specificity"],
           cm$byClass["F1"]) 
  return(test)
}
```

```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
metrics.mod <- data.frame(#glm.mod = cm.metric(glm.cm),
                          glm.mod11 = cm.metric(glm11.cm),
                          glm.mod12 = cm.metric(glm12.cm),
                          ridge.mod1 = cm.metric(ridge.cm1),
                          ridge.mod2 = cm.metric(ridge.cm2),
                          lasso.mod1 = cm.metric(lasso.cm1),
                          lasso.mod2 = cm.metric(lasso.cm2),
                          pls.mod1 = cm.metric(pls.cm1),
                          pls.mod2 = cm.metric(pls.cm2))
metrics.mod
```

With precision and specificity equal to 1, the ridge.mod2 model is overfitting. But glm.mod12 has the best accuracy, precision, sensivity, and specificity.

### Using pROC package. 
We can plot the ROC curve and extract the AUC value.
```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
library(pROC)
library(dplyr)
prediction <- data.frame(TARGET = testing1$TARGET,
                         glm1 = glm11.pred, 
                         gml2 = glm12.pred, 
                         pls1 = pls1.pred,
                         pls2 = pls2.pred,
                         rp1 = ridge.pred1, 
                         rp2 = ridge.pred2, 
                         lp1 = lasso.pred1, 
                         lp2 = lasso.pred2)

```

```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}

```


```{r, eval=TRUE, message=FALSE, warning=FALSE, fig.cap= "Best Model with AUC", echo=FALSE, results='show'}
## With ggplot2 ##
library(ggplot2)
# Create multiple curves to plot
roc1 <- roc(TARGET ~., data = prediction)
ggroc(roc1)
```
The glm model has the best Area Under the Curve.

### We run the glm model with the entire dataset

#### Second glm model
```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
best.model <-  glm(formula = TARGET ~ SEX + AGEG.F7 + X_RACEGR3 + EDUCAL + X_INCOMG + 
    BRONCH + DUR.30D + INCINDT + LAST.MD + LAST.MED + LAST.SYMP + 
    COMPASTH + WORKTALK, family = binomial, data = asth.mgt.ad.min35)
summary(best.model)
```

```{r, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='show'}
exp(coef(best.model))
```






